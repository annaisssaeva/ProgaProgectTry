{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pymorphy2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jIS-bUrcQRJ",
        "outputId": "ea8f021b-656a-49fd-83a5-5792bdda302b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pymorphy2 in /usr/local/lib/python3.9/dist-packages (0.9.1)\n",
            "Requirement already satisfied: dawg-python>=0.7.1 in /usr/local/lib/python3.9/dist-packages (from pymorphy2) (0.7.2)\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.9/dist-packages (from pymorphy2) (0.6.2)\n",
            "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in /usr/local/lib/python3.9/dist-packages (from pymorphy2) (2.4.417127.4579844)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создаем базу данных, в которой будем хранить информацию о песнях: айди, название, текст и ключевые слова"
      ],
      "metadata": {
        "id": "BeyVIhwtdtzb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "con = sqlite3.connect('songs.db')\n",
        "cur = con.cursor()\n",
        "\n",
        "cur.execute(\"\"\"\n",
        "CREATE TABLE songs (\n",
        "    song_id INT,\n",
        "    name TEXT,\n",
        "    lyrics TEXT,\n",
        "    keywords TEXT,\n",
        "    PRIMARY KEY (song_id)\n",
        "\n",
        ")\n",
        "\"\"\")\n",
        "con.commit()"
      ],
      "metadata": {
        "id": "FREP6CCbTzFC"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-kXFgpRcH4d",
        "outputId": "4bad7a7c-2cdf-44dd-83bf-02933bd0d7f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from nltk.tokenize import wordpunct_tokenize\n",
        "from pymorphy2 import MorphAnalyzer\n",
        "import numpy as np\n",
        "\n",
        "#грузим стоп-слова\n",
        "nltk.download('stopwords')\n",
        "stops = stopwords.words()\n",
        "tfidf = TfidfVectorizer(\n",
        "    analyzer=\"word\",\n",
        "    stop_words=stops\n",
        ")\n",
        "\n",
        "data = []\n",
        "id = 1\n",
        "#для каждой песни в файле заводим переменные с названием, текстом\n",
        "#и ключевыми словами\n",
        "with open(\"lyrics.txt\", \"r\", encoding=\"utf-8\") as file:\n",
        "    for song in file.read().split(\"\\n\\n\\n\"):\n",
        "        name = song.split(\"\\n\")[0]\n",
        "        lyrics = \" \".join(song.split(\"\\n\")[1:])\n",
        "\n",
        "        #лемматизируем текст\n",
        "        morph = MorphAnalyzer()\n",
        "        lyrics_preprocessed = []\n",
        "        l_tokens = wordpunct_tokenize(lyrics)\n",
        "        l_lemmatized = \" \".join([morph.parse(item)[0].normal_form for item in l_tokens])\n",
        "        lyrics_preprocessed.append(l_lemmatized)\n",
        "        lyrics_tfidf = tfidf.fit_transform(lyrics_preprocessed)\n",
        "\n",
        "        #получаем термы\n",
        "        def get_top_tf_idf_words(tfidf_vector, feature_names, top_n):\n",
        "            sorted_nzs = np.argsort(tfidf_vector.data)[:-(top_n + 1):-1]\n",
        "            return feature_names[tfidf_vector.indices[sorted_nzs]]\n",
        "        feature_names = np.array(tfidf.get_feature_names_out())\n",
        "        \n",
        "        #кладем в ключевые слова 20 главных термов\n",
        "        words = get_top_tf_idf_words(lyrics_tfidf, feature_names, 20)\n",
        "        words = str(\" \".join(words))\n",
        "        info = [id, name, lyrics, words]\n",
        "        data.append(info)\n",
        "        #увеличиваем айди для следующей песни\n",
        "        id += 1\n",
        "\n",
        "#кладем данные в базу данных\n",
        "cur.executemany(\"INSERT or IGNORE INTO songs VALUES (?, ?, ?, ?)\", data)\n",
        "        \n",
        "con.commit()"
      ]
    }
  ]
}